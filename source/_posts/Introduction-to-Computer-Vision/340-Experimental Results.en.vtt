WEBVTT
Kind: captions
Language: en

00:00:00.510 --> 00:00:04.210
Here's a very nice table of some experimental results.

00:00:04.210 --> 00:00:08.690
Just shows you the different kinds of perturbations that they did.

00:00:08.690 --> 00:00:09.220
Okay?

00:00:09.220 --> 00:00:12.080
And they're talking about different ways of comparing the matches.

00:00:12.080 --> 00:00:17.170
About whether you just, you know, do you get the right location and scale?

00:00:17.170 --> 00:00:19.310
And what about orientation?

00:00:19.310 --> 00:00:22.280
The thing that really matters is that you're doing all these different things.

00:00:22.280 --> 00:00:26.479
You're looking at changes in intensities, rotations, scalings,

00:00:26.479 --> 00:00:28.720
stretching 10% noise.

00:00:28.720 --> 00:00:31.360
And you can see if you do all of those things,

00:00:31.360 --> 00:00:34.250
depending upon whether you're looking at just location scale or

00:00:34.250 --> 00:00:40.030
including orientation, you still get above a 70% match.

00:00:40.030 --> 00:00:41.750
And that's pretty remarkable.

00:00:41.750 --> 00:00:44.050
In fact, there's a nice figure that comes from here.

00:00:44.050 --> 00:00:47.192
So, here's an original image, and drawn on on top of this pic,

00:00:47.192 --> 00:00:49.550
in fact you can almost not see the picture underneath.

00:00:49.550 --> 00:00:51.830
There are all these feature points, okay?

00:00:51.830 --> 00:00:56.600
And, what they did is they took the picture and they rotated it 15 degrees.

00:00:56.600 --> 00:00:58.424
They scaled it down 90%.

00:00:58.424 --> 00:01:01.510
They stretched it 10%.

00:01:01.510 --> 00:01:03.680
Okay another, an extra 10%.

00:01:03.680 --> 00:01:06.990
They changed the brightness down by 10%, changed the contrast, multiplied out,

00:01:06.990 --> 00:01:09.070
and they added some noise.

00:01:09.070 --> 00:01:12.820
And then they went back and they took a look at all their feature points.

00:01:12.820 --> 00:01:14.430
And how well did it match?

00:01:14.430 --> 00:01:15.770
Well I love this little animation.

00:01:15.770 --> 00:01:18.935
See the whole thing flies in here and says 78%.

00:01:20.210 --> 00:01:21.160
That's pretty cool.

00:01:21.160 --> 00:01:25.130
What that's showing you, is that you have this very robust descriptor, and

00:01:25.130 --> 00:01:30.120
yet it's distinctive enough that you can find the correct matches.

00:01:30.120 --> 00:01:32.830
Here's another example again from the paper.

00:01:32.830 --> 00:01:35.340
What you're looking for are these little things.

00:01:35.340 --> 00:01:38.580
Okay, so this is a little piece of the house this is a little piece of

00:01:38.580 --> 00:01:41.260
the totem pole, this is something else that was on the totem pole.

00:01:41.260 --> 00:01:44.660
In fact, it's a little hard to see, so I put these little colored dots.

00:01:44.660 --> 00:01:48.120
So what they're look, so we're looking for these patches over here.

00:01:48.120 --> 00:01:50.860
What you're going to do is you're going to create little SIFT features on

00:01:50.860 --> 00:01:52.030
all these things.

00:01:52.030 --> 00:01:55.340
And you're going to look for those patches in the corresponding image.

00:01:55.340 --> 00:01:56.930
And what are you going to find?

00:01:56.930 --> 00:01:57.820
Voila!

00:01:57.820 --> 00:02:00.200
Basically, the thing works, which is not a surprise.

00:02:00.200 --> 00:02:02.340
It came from the paper where they're claiming it.

00:02:02.340 --> 00:02:06.440
By the way SIFT is actually intellectual property owned by the University of

00:02:06.440 --> 00:02:07.460
British Columbia.

00:02:07.460 --> 00:02:08.732
So before you go implement it and

00:02:08.732 --> 00:02:11.095
put it in your iPhone in order to do something clear.

00:02:11.095 --> 00:02:12.510
Make sure you hire a really good lawyer.

