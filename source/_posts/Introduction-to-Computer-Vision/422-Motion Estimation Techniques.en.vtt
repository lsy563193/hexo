WEBVTT
Kind: captions
Language: en

00:00:00.340 --> 00:00:03.360
So for the remainder of this lesson,
and then the next one.

00:00:03.360 --> 00:00:04.630
Oh, and then the next one.

00:00:04.630 --> 00:00:06.400
Oh, then the next one too.

00:00:06.400 --> 00:00:08.850
We're going to be talking
about motion estimation.

00:00:08.850 --> 00:00:13.660
Basically, given a sequence, tell me
what moved, tell me how it moved.

00:00:15.180 --> 00:00:18.290
Generally, you can say there are two
different approaches to this.

00:00:18.290 --> 00:00:20.969
The first approach,
involves feature-based methods.

00:00:20.969 --> 00:00:23.820
Now feature-based methods
are just what you might think.

00:00:23.820 --> 00:00:27.430
Extract some visual features
like corners, textured areas.

00:00:27.430 --> 00:00:29.460
Oh yeah, we know all about that.

00:00:29.460 --> 00:00:31.680
And track them across multiple frames.

00:00:31.680 --> 00:00:34.460
So that is find them from
one frame into another.

00:00:34.460 --> 00:00:36.640
Oh, we know all about that too.

00:00:36.640 --> 00:00:39.950
And that will give you what's
called a sparse motion field.

00:00:39.950 --> 00:00:44.700
That is, you you don't have
the motion of all the points.

00:00:44.700 --> 00:00:48.140
You have a motion of a bunch of
points that were good to track.

00:00:48.140 --> 00:00:48.640
All right?

00:00:48.640 --> 00:00:52.460
But that works really well when image
motion is large, so you move like

00:00:52.460 --> 00:00:57.550
tens of pixels, and you'll have
a significant change between frames.

00:00:57.550 --> 00:01:02.870
The other method class of methods are
what are called direct or dense methods.

00:01:02.870 --> 00:01:07.590
In dense methods, you sort of directly
recovering the motion of every pixel

00:01:07.590 --> 00:01:10.860
of each pixel from the,

00:01:10.860 --> 00:01:15.110
the fancy work is spatio-temporal
image brightness variation.

00:01:15.110 --> 00:01:18.740
So another way,
remember that volume X, Y, and T?

00:01:18.740 --> 00:01:23.110
So you can think of gradients, you
can think of flow within that volume,

00:01:23.110 --> 00:01:27.130
and what you're trying to do is you're
trying to recover that flow based upon

00:01:27.130 --> 00:01:28.640
how the appearance changes over time.

00:01:29.650 --> 00:01:31.520
It gives you a very dense motion field,
but

00:01:31.520 --> 00:01:33.960
it can be sensitive to
appearance changes.

00:01:33.960 --> 00:01:35.570
This type of analysis is suitable for

00:01:35.570 --> 00:01:40.090
video where you're getting
samples very quickly.

00:01:40.090 --> 00:01:43.076
So things don't move very much in time.

00:01:43.076 --> 00:01:47.470
And, in fact, if things are somewhat
smooth in time and space, I could say,

00:01:47.470 --> 00:01:50.700
well, from one frame to a next, I can
talk about how things are moving, like,

00:01:50.700 --> 00:01:52.200
say, a first derivative.

00:01:52.200 --> 00:01:57.000
If you're worried that a Taylor series
expansion is in our future today, well,

00:01:57.000 --> 00:01:58.090
maybe tomorrow?

00:01:58.090 --> 00:01:59.450
Yes, okay.

00:01:59.450 --> 00:02:02.990
But the idea is that it's good for
nice, dense, smoothly moving things.

