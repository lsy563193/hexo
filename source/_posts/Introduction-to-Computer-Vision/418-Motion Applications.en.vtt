WEBVTT
Kind: captions
Language: en

00:00:00.270 --> 00:00:03.363
Let's talk a little bit about
the processing of video and

00:00:03.363 --> 00:00:06.393
some of the applications or
not just applications, but

00:00:06.393 --> 00:00:09.182
the general computations
that we would want to do.

00:00:09.182 --> 00:00:11.782
And then we could talk about how
motion could be used in order to,

00:00:11.782 --> 00:00:13.760
or the motion processing
be used to do that.

00:00:13.760 --> 00:00:16.833
So, a simple one is
background subtraction.

00:00:16.833 --> 00:00:19.977
So you might have a situation where
you've got a static camera and

00:00:19.977 --> 00:00:23.065
a the background is considered
to be a static background and

00:00:23.065 --> 00:00:25.890
I've got some object
moving in the foreground.

00:00:25.890 --> 00:00:29.026
And my goal is to pull out
the foreground object,

00:00:29.026 --> 00:00:32.021
the moving thing from
the static background.

00:00:32.021 --> 00:00:35.000
So, I may be able to track it or
model its dynamics or recognize it or

00:00:35.000 --> 00:00:38.200
something else that's,
that's focused on the object.

00:00:38.200 --> 00:00:42.695
Another interesting application might
be what we call shot detection and

00:00:42.695 --> 00:00:44.731
that's illustrated here.

00:00:44.731 --> 00:00:48.971
So the idea is here we have a bunch
of frames that are in a video and

00:00:48.971 --> 00:00:53.771
commercially produced video is usually
made up of a sequence of shots,

00:00:53.771 --> 00:00:56.970
each shot coming from
a particular camera.

00:00:56.970 --> 00:00:59.686
The camera might be moving,
it might be panning.

00:00:59.686 --> 00:01:04.900
It might be dallying moving, translating
and then you'll cut to a different shot.

00:01:04.900 --> 00:01:09.044
And in this particular case,
our shot boundary is shown right here.

00:01:09.044 --> 00:01:11.853
Right?
All of these are taken from one camera

00:01:11.853 --> 00:01:14.116
shot and these are taken from another.

00:01:14.116 --> 00:01:17.340
Often, it looks to you like they're
taken one right after another.

00:01:17.340 --> 00:01:19.305
But in reality, they changed everything.

00:01:19.305 --> 00:01:21.610
They moved the camera around,
changed the actor.

00:01:21.610 --> 00:01:23.611
Redid his makeup,
he went and got a smoke or

00:01:23.611 --> 00:01:25.508
whatever it is they're smoking on set.

00:01:25.508 --> 00:01:28.395
And then they came back and
they did the, the next shot and

00:01:28.395 --> 00:01:30.550
they just cut them together.

00:01:30.550 --> 00:01:34.934
And if you think about what that would
look like to a computer in one case,

00:01:34.934 --> 00:01:39.657
I might have a nice, smooth background
moving with some objects moving within

00:01:39.657 --> 00:01:43.704
it and then there's this rapid change
and I might have another camera,

00:01:43.704 --> 00:01:47.090
which might not be static,
it might be moving as well.

00:01:47.090 --> 00:01:50.990
And the analysis of that motion might
allow you to do the shot detection.

00:01:50.990 --> 00:01:53.532
So we have background subject,
subtraction,

00:01:53.532 --> 00:01:55.635
we have shot boundary detection.

00:01:55.635 --> 00:01:59.701
Maybe we have a bunch of objects that
are moving in different ways within

00:01:59.701 --> 00:02:03.494
a scene and we'd like to separate
out each of those objects and

00:02:03.494 --> 00:02:06.166
that's referred to as
motion segmentation.

00:02:06.166 --> 00:02:10.600
Motion segmentation is you
segment the video into multiple,

00:02:10.600 --> 00:02:14.470
what we call coherently moving objects.

00:02:14.470 --> 00:02:15.753
All right?
So they're each moving, but

00:02:15.753 --> 00:02:17.470
they're moving in an independent way.

00:02:17.470 --> 00:02:19.032
So here's an example.

00:02:19.032 --> 00:02:23.725
And what's funny is this is a static
image of a snake and a mongoose taken

00:02:23.725 --> 00:02:29.220
off the web and you could imagine trying
to separate these out just spatially.

00:02:29.220 --> 00:02:30.723
In fact, you can sort of do that.

00:02:30.723 --> 00:02:32.790
But in fact,
the color of the mongoose and

00:02:32.790 --> 00:02:35.940
the snake is very similar to
the color of the background.

00:02:35.940 --> 00:02:39.052
And if you were to track these things,
you would see pixels coming and going.

00:02:39.052 --> 00:02:41.441
But if you actually were
to look at the motion,

00:02:41.441 --> 00:02:44.753
you would see the motion of the snake
as being a coherent thing and

00:02:44.753 --> 00:02:47.574
the motion of the mongoose as
being a coherent thing and

00:02:47.574 --> 00:02:50.720
you would be able to use motion
to segment out those objects.

